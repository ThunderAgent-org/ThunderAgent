# SWE-bench 评估配置文件
# 定义 vLLM 本地服务器的 LLM 配置

[llm.vllm_local]
model = "/mnt/shared/Qwen3-Coder-30B-A3B-Instruct"
api_key = "EMPTY"
base_url = "http://127.0.0.1:8100/v1"
temperature = 0.0
top_p = 1.0
max_output_tokens = 8192
timeout = 600
num_retries = 5

# 可选：如果需要过滤特定的实例 ID，取消下面的注释
# selected_ids = []

# 可选：如果需要过滤特定的仓库，取消下面的注释
# selected_repos = []

