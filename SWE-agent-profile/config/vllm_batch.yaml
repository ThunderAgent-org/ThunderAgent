vllm:
  model: /data/models/GLM-4.5-FP8
  host: 0.0.0.0
  connect_host: 127.0.0.1
  port: 8000
  wait_timeout: 240
  tokenizer: /data/models/GLM-4.5-FP8
  tensor_parallel: 4
  gpu_memory_utilization: 0.9
  dtype: auto
  max_model_len: null
  extra_args:
    - --enable-auto-tool-choice
    - --enable-chunked-prefill
    - --enable-prefix-caching
    - --tool-call-parser
    - glm45
    - --pipeline-parallel-size
    - 2

  env: {}

batch:
  sweagent_config: config/vllm_local.yaml
  args:
    - --instances.type
    - swe_bench
    - --instances.subset
    - lite
    - --instances.split
    - test
    - --instances.slice
    - 64:74
  runs:
    - label: bs1
      args: [--num_workers, 1, --suffix, bs1]
    - label: bs4
      args: [--num_workers, 4, --suffix, bs4]
    - label: bs8
      args: [--num_workers, 8, --suffix, bs8]
    - label: bs16
      args: [--num_workers, 16, --suffix, bs16]
    - label: bs32
      args: [--num_workers, 32, --suffix, bs32]
    - label: bs64
      args: [--num_workers, 64, --suffix, bs64]
  env: {}      